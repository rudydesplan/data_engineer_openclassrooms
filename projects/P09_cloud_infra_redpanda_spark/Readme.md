------

# Projet 9 - Exercice 2 : POC Pipeline ETL Temps R√©el (Redpanda & Spark Streaming)

Ce projet est une Preuve de Concept (POC) d'un pipeline ETL (Extract, Transform, Load) en temps r√©el. Il simule l'ingestion de tickets de support client, les traite en continu pour enrichir les donn√©es et calculer des agr√©gations complexes, et stocke les m√©triques r√©sultantes sous format JSON, simulant un chargement vers un Data Lake (S3).

## üìë Vue d'ensemble

Le but de ce pipeline est de transformer un flux brut d'√©v√©nements (tickets de support) en m√©triques exploitables pour l'analyse m√©tier (BI), avec une latence faible (micro-batchs de 30 secondes).

### Technologies cl√©s

- **Docker & Docker Compose :** Orchestration des conteneurs pour un d√©ploiement facile.
- **Python (Faker & Confluent Kafka) :** G√©n√©ration de donn√©es synth√©tiques et production vers le bus d'√©v√©nements.
- **Redpanda Cloud :** Plateforme de streaming d'√©v√©nements compatible Kafka (utilis√©e ici en mode SaaS).
- **PySpark Structured Streaming :** Moteur de traitement de donn√©es en temps r√©el pour le nettoyage, l'enrichissement et l'agr√©gation.

## üèóÔ∏è Architecture

L'architecture, con√ßue pour √™tre d√©ploy√©e sur AWS (ECS Fargate, S3), est simul√©e localement via Docker Compose.

*(Note : L'impl√©mentation actuelle d√©pose les fichiers JSON localement, simulant l'√©tape "Write Metrics" vers S3).*

**Flux de donn√©es :**

1. **Producteur (Ingest) :** Un script Python g√©n√®re des tickets de support al√©atoires (JSON) et les envoie de mani√®re s√©curis√©e (SASL/SSL) vers un topic `client_tickets` sur Redpanda Cloud.
2. **Hub de Streaming :** Redpanda Cloud re√ßoit et met en m√©moire tampon les messages.
3. **Consommateur & Traitement (Subscribe & Process) :**
   - Spark Structured Streaming s'abonne au topic Redpanda.
   - Toutes les **30 secondes** (trigger micro-batch), Spark traite les nouvelles donn√©es.
   - **Transformations :** Conversion de timestamps, extraction de date/heure, mapping des √©quipes de support, calcul des SLA (Service Level Agreement) et scoring de priorit√©.
   - **Agr√©gations :** Calcul de m√©triques complexes (total, par heure, par jour, par type, par √©quipe, moyennes/m√©dianes des SLA, etc.).
4. **Stockage (Write) :** √Ä la fin de chaque micro-batch, un fichier JSON contenant toutes les m√©triques agr√©g√©es est √©crit dans un volume local partag√©.

```mermaid
graph LR
    %% Main AWS Cloud Boundary
    subgraph AWS_Cloud["AWS Cloud (eu-central-1)"]
        style AWS_Cloud fill:#F2F3F3,stroke:#232F3E,stroke-width:2px

        %% VPC Boundary
        subgraph VPC["VPC"]
            style VPC fill:#E6F2F8,stroke:#007CBC,stroke-width:3px

            %% Private Subnet Boundary
            subgraph Private_Subnet["Private Subnet (Processing & Producers)"]
                style Private_Subnet fill:none,stroke:#007CBC,stroke-width:2px,stroke-dasharray: 5 5
                Producer["Amazon ECS<br>Fargate Task<br>(Producer)"]
                Consumer["Amazon ECS<br>Spark Streaming<br>(Consumer)"]
            end

            %% Redpanda Cloud (External Service)
            Redpanda["Redpanda Cloud<br>Kafka Topic:<br>client_tickets"]
        end
    end

    %% Data Storage & Analytics Boundary
    subgraph Data_Storage_Analytics["Data Storage & Analytics"]
        style Data_Storage_Analytics fill:#E6F2F8,stroke:#3F8624,stroke-width:2px,stroke-dasharray: 5 5
        S3["Amazon S3<br>Bucket: metrics<br>(JSON)"]
        Analytics["QuickSight / Athena<br>Dashboards<br>(Consumption)"]
    end

    %% Data Flow Connections
    Producer -->|"1. Ingest (SASL/SSL)<br>JSON: ticket_id..."| Redpanda
    Redpanda -->|"2. Subscribe<br>(Micro-batch 30s)"| Consumer
    Consumer -->|"3. Write Metrics<br>(JSON files)"| S3
    S3 -->|"4. Read/Query"| Analytics

    %% Define styles for nodes
    class Producer,Consumer ecs;
    class S3 s3;
    class Analytics analytics;
    class Redpanda redpanda;

    classDef ecs fill:#FF9900,stroke:#232F3E,stroke-width:2px,color:white,font-weight:bold;
    classDef s3 fill:#3F8624,stroke:#232F3E,stroke-width:2px,color:white,font-weight:bold;
    classDef analytics fill:#693CC5,stroke:#232F3E,stroke-width:2px,color:white,font-weight:bold;
    classDef redpanda fill:#C9211E,stroke:#232F3E,stroke-width:2px,color:white,font-weight:bold;
```



## üìÇ Structure du Projet

Bash

```
.
‚îú‚îÄ‚îÄ docker-compose.yml       # Orchestration des services Producer et Spark
‚îú‚îÄ‚îÄ Pipeline Diagram.png     # Diagramme visuel de l'architecture
‚îú‚îÄ‚îÄ producer/                # Dossier du conteneur Producteur
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile           # D√©finition de l'image Docker du producteur
‚îÇ   ‚îú‚îÄ‚îÄ producer_redpanda.py # Script Python de g√©n√©ration et d'envoi des tickets
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt     # D√©pendances Python (confluent-kafka, faker)
‚îî‚îÄ‚îÄ spark/                   # Dossier du conteneur Spark
    ‚îú‚îÄ‚îÄ Dockerfile           # D√©finition de l'image Docker Spark (avec connecteurs Kafka)
    ‚îú‚îÄ‚îÄ traitement_spark.py  # Script PySpark de streaming et d'agr√©gation
    ‚îî‚îÄ‚îÄ ticket_metrics_json/ # DOSSIER DE SORTIE : contient les fichiers JSON g√©n√©r√©s
```

## üöÄ Installation et Utilisation (Docker Compose)

### Pr√©requis

- Docker et Docker Compose install√©s sur votre machine.
- Une connexion Internet active (les conteneurs doivent se connecter √† Redpanda Cloud externe).

### Instructions de d√©marrage

1. **Cloner ou t√©l√©charger** ce d√©p√¥t sur votre machine.

2. **Ouvrir un terminal** √† la racine du projet (l√† o√π se trouve `docker-compose.yml`).

3. **Construire les images Docker :**

   Bash

   ```
   docker-compose build
   ```

4. **D√©marrer le pipeline :**

   Bash

   ```
   docker-compose up
   ```

> **Note sur le d√©marrage :** Le service `producer` est configur√© pour attendre que le service `spark` soit "healthy" (op√©rationnel et capable de se connecter √† Redpanda) avant de d√©marrer. Il est normal de voir des logs d'attente au d√©but.

Pour arr√™ter le pipeline proprement : Faites `CTRL+C` dans le terminal, puis ex√©cutez `docker-compose down`.

## ‚úÖ Preuve de Fonctionnalit√©

Comment v√©rifier que le pipeline fonctionne correctement ?

### 1. V√©rification des Logs (Terminal)

- **Logs du Producteur (`ticket_producer`) :** Vous verrez des messages indiquant l'envoi de tickets en continu.

  Plaintext

  ```
  ticket_producer | Produced: {'ticket_id': '...', 'priority': 'high', ...}
  ticket_producer | üì® Delivered to client_tickets [0] @ offset 12345
  ```

- **Logs de Spark (`spark_stream_processor`) :** Toutes les 30 secondes, vous verrez le d√©marrage d'un micro-batch et la confirmation de l'√©criture du fichier JSON.

  Plaintext

  ```
  spark_stream_processor | ...
  spark_stream_processor | [‚úì] JSON metrics written ‚Üí /tmp/ticket_metrics_json/batch_00042.json
  ```

### 2. V√©rification des Sorties (Fichiers JSON)

La preuve ultime du fonctionnement est la g√©n√©ration des fichiers de m√©triques.

1. Pendant que le pipeline tourne, naviguez dans votre explorateur de fichiers vers le dossier du projet : `spark/ticket_metrics_json/`.
2. Vous verrez appara√Ætre de nouveaux fichiers `batch_XXXXX.json` toutes les ~30 secondes.
3. **Ouvrez un de ces fichiers.** Il contiendra la structure agr√©g√©e d√©finie dans le script Spark, par exemple :

JSON

```
{
    "batch_id": 42,
    "total_tickets": 150,
    "tickets_per_hour": [
        {"hour": 10, "tickets_per_hour": 45},
        {"hour": 11, "tickets_per_hour": 105}
    ],
    "by_team": [
        {"support_team": "Security Ops Center", "count_by_support_team": 12},
        {"support_team": "Team Tech 1", "count_by_support_team": 80}
        // ... autres √©quipes
    ],
    "sla_mean": 24.5,
    "sla_median": 4.0,
    "priority_score_mean": 2.8,
    // ... autres m√©triques
}
```

La pr√©sence et le contenu de ces fichiers confirment que les donn√©es sont ing√©r√©es, transform√©es, agr√©g√©es et stock√©es avec succ√®s.