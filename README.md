# Portfolio — Parcours Data Engineer (OpenClassrooms)

> **Objectif**  
Ce dépôt sert de **vitrine** de mon parcours Data Engineer : il présente les projets réalisés (P2 à P13) sous forme de **page d’orientation**.  
Chaque projet est documenté en détail dans son **dossier dédié** avec un `README.md` (contexte, objectif, démarche, outils, compétences, résultats, recul) ainsi que la présentation.

---

## Table des matières
- [Organisation du repo](#organisation-du-repo)
- [Synthèse des compétences](#synthèse-des-compétences)
- [Projets](#projets)

---

## Organisation du repo

- `README.md` *(ce fichier — page d’orientation)*
- `projects/`
  - `P02_education/` — Analyse de données (Python/EDA)
  - `P03_sql_real_estate/` — SQL & modélisation relationnelle (3NF)
  - `P04_audit_olap/` — Audit data / OLAP (rétro-engineering)
  - `P05_mongo_migration/` — Migration NoSQL (MongoDB) + Docker
  - `P06_energy_ml_api/` — ML + API (BentoML) + déploiement
  - `P07_nosql_airbnb/` — NoSQL analytics + BI + réplication/sharding
  - `P08_data_infra_testing/` — Infrastructure data + tests + monitoring
  - `P09_cloud_infra_redpanda_spark/` — Cloud hybride + streaming (Redpanda) + PySpark
  - `P10_orchestration_kestra/` — Orchestration (Kestra) + data quality tests
  - `P11_rag_system/` — Système RAG (LangChain + Mistral + FAISS)
  - `P12_infra_project/` — Gestion de projet infra : pipeline + monitoring + BI
  - `P13_mvp_portfolio/` — Passage IA POC → MVP + portfolio

---

## Synthèse des compétences

Compétences consolidées sur le parcours (illustrées dans les projets) :

- **Analyse & préparation de données** : EDA, nettoyage, valeurs manquantes, corrélations, features
- **SQL & modélisation relationnelle** : 3NF, PK/FK, contraintes, requêtes analytiques
- **Audit & rétro-engineering** : compréhension d’écosystèmes data, logs, tests de cohérence, recommandations
- **NoSQL MongoDB** : import, requêtes CLI, analytics Python/Polars, BI, réplication, sharding
- **Reproductibilité & conteneurisation** : Docker/Docker Compose, environnements isolés
- **ML appliqué + API** : modélisation supervisée, validation croisée, industrialisation via API (BentoML), déploiement
- **Infra data & tests** : ingestion (Airbyte), stockage (Mongo/DocumentDB), scripts de tests, monitoring/logs
- **Cloud & streaming** : architecture hybride, streaming (Redpanda), traitement PySpark, export
- **Orchestration & data quality** : workflows orchestrés (Kestra), tests automatisés intégrés au pipeline
- **IA/RAG & industrialisation** : pipeline RAG, index vectoriel, évaluation, passage POC → MVP (architecture, coûts, run)

---

## Projets

> Chaque lien pointe vers le dossier du projet (et son README dédié).

- **P2 — Analyse de données de systèmes éducatifs**  
  `projects/P02_education/`

- **P3 — SQL & création de BDD (Laplace Immo)**  
  `projects/P03_sql_real_estate/`

- **P4 — Audit d’un environnement de données (SuperSmartMarket)**  
  `projects/P04_audit_olap/`

- **P5 — Migration de données médicales en NoSQL (MongoDB + Docker)**  
  `projects/P05_mongo_migration/`

- **P6 — Prédiction conso bâtiments + API (BentoML) + déploiement cloud**  
  `projects/P06_energy_ml_api/`

- **P7 — NoSQL (NosCités) : requêtes, BI, réplication & sharding**  
  `projects/P07_nosql_airbnb/`

- **P8 — Construire & tester une infrastructure data (Airbyte, Mongo/DocumentDB, monitoring)**  
  `projects/P08_data_infra_testing/`

- **P9 — Modéliser une infrastructure cloud + streaming (Redpanda) + PySpark**  
  `projects/P09_cloud_infra_redpanda_spark/`

- **P10 — Orchestration des flux (Kestra) + data quality tests**  
  `projects/P10_orchestration_kestra/`

- **P11 — Concevoir & déployer un système RAG (LangChain + Mistral + FAISS)**  
  `projects/P11_rag_system/`

- **P12 — Gérer un projet d’infrastructure : pipeline + monitoring + PowerBI**  
  `projects/P12_infra_project/`

- **P13 — Passer un système IA du POC au MVP + portfolio**  
  `projects/P13_mvp_portfolio/`
